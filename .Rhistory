vmpfcGambling <- vmpfcGambling[vmpfcGambling$validTrial==1,]
vmpfcGambling <- vmpfcGambling[(vmpfcGambling$opt1Prob < 1),]
vmpfcGambling <- vmpfcGambling[(vmpfcGambling$opt2Prob < 1),]
neuron = vmpfcGambling$neuron
nrows = dim(vmpfcGambling)[1]
#reward vs probability (epoch 1)
setName = rep('vmpfcGambling_rew_prob', nrows)
X1= vmpfcGambling$opt1Rew
X2= vmpfcGambling$opt1Prob
spikes = rowSums(vmpfcGambling[,grep("^offerPsth251$", colnames(vmpfcGambling)):grep("^offerPsth275$", colnames(vmpfcGambling))])
regInd = rep(0,nrows)
data = rbind(data, cbind(setName, neuron, spikes, X1, X2, as.integer(regInd)))
#value option 1, value option 2 (epoch 2)
setName = rep('vmpfcGambling_ev1_ev2', nrows)
X1= vmpfcGambling$opt1EV
X2= vmpfcGambling$opt2EV
spikes = rowSums(vmpfcGambling[,grep("^offerPsth301$", colnames(vmpfcGambling)):grep("^offerPsth325$", colnames(vmpfcGambling))])
regInd = rep(0,nrows)
data = rbind(data, cbind(setName, neuron, spikes, X1, X2, as.integer(regInd)))
#left rew vs right rew (FIRST & SECOND EPOCH)
setName = rep('vmpfcGambling_leftEV_rightEV', nrows)
leftEV = vmpfcGambling$opt1EV
leftEV[vmpfcGambling$opt1Side != 1] = vmpfcGambling$opt2EV[vmpfcGambling$opt1Side != 1]
rightEV = vmpfcGambling$opt2EV
rightEV[vmpfcGambling$opt1Side != 1] = vmpfcGambling$opt1EV[vmpfcGambling$opt1Side != 1]
X1= rep(leftEV, 2)
X2= rep(rightEV, 2)
regInd = c(vmpfcGambling$opt1Side == 2, vmpfcGambling$opt1Side == 1)
spikes = c(rowSums(vmpfcGambling[,grep("^offerPsth251$", colnames(vmpfcGambling)):grep("^offerPsth275$", colnames(vmpfcGambling))]),
rowSums(vmpfcGambling[,grep("^offerPsth301$", colnames(vmpfcGambling)):grep("^offerPsth325$", colnames(vmpfcGambling))]))
neuron = rep(vmpfcGambling$neuron,2)
data = rbind(data, cbind(setName, neuron, spikes, X1, X2, as.integer(regInd)))
#chosen value vs offered value (epoch 1 and choice epoch)
setName = rep('vmpfcGambling_firstEV_chosenEV', nrows*2)
chosenEV = vmpfcGambling$opt1EV
chosenEV[vmpfcGambling$chosenOpt == 2] = vmpfcGambling$opt2EV[vmpfcGambling$chosenOpt == 2]
X1= c(vmpfcGambling$opt1EV,rep(0,nrows))
X2= c(rep(0,nrows),chosenEV)
spikes = c(rowSums(vmpfcGambling[,grep("^offerPsth251$", colnames(vmpfcGambling)):grep("^offerPsth275$", colnames(vmpfcGambling))]),
rowSums(vmpfcGambling[,grep("^offerPsth331$", colnames(vmpfcGambling)):grep("^offerPsth356$", colnames(vmpfcGambling))]))
neuron = rep(vmpfcGambling$neuron,2)
regInd = c(rep(0,nrows), rep(1,nrows))
data = rbind(data, cbind(setName, neuron, spikes, X1, X2, as.integer(regInd)))
save(data,file=paste(dataDir, 'regressorInput.RData', sep = ""))
## RUN THE REGRESSION ON EVERYTHING
names(data)[6] <- 'regInd'
#It's unclear why this needs to be done, but otherwise ddply throws an error
names(data$setName) <-NULL
names(data$neuron) <-NULL
names(data$spikes) <-NULL
names(data$X1) <-NULL
names(data$X2) <-NULL
names(data$regInd) <-NULL
regdata = ddply(data, c("setName", "neuron"), runReg)
#remove any nans caused by bad cells
regdata <- regdata[complete.cases(regdata),]
save(regdata,file=paste(dataDir, 'regdata2.RData', sep = ""))
save(regdata,file=paste(dataDir, 'regdata.RData', sep = ""))
setwd('/Users/tommyblanchard/Dropbox/ObserveBetModel')
library(rstan)
d = runModel()
#Daniel Navarro's code, taken from https://bitbucket.org/dannavarro/observe-or-bet/overview
# return a list of all inputs to the model (besides the sequence of outcomes)
getModelInputs <- function(
# important model parameters (to be estimated)
changeProb=.025,      # probability of a change
evidenceThreshold=.8, # required posterior certainty to bet
# auxiliary (fixed) parameters
priorGuess = .5,      # auxiliary: prior guess about the true rate
priorCertainty = 10,  # auxiliary: concentration about that prior
# simulation parameters
nParticles = 10000    # number of particles to use
) {
list( changeProb=changeProb, evidenceThreshold=evidenceThreshold,
priorGuess=priorGuess, priorCertainty=priorCertainty,
nParticles=nParticles
)
}
# define a function to run the model
runModel <- function( par=getModelInputs(), seq=makeSequence(), plot=TRUE ) {
# --- functions ---
# prior distribution over theta is a beta distribution concentrated around
# the "priorGuess", with precision parameter "priorCertainty"
sampleFromRatePrior <- function( n=par$nParticles ) {
return( rbeta( n, par$priorGuess*(par$priorCertainty), (1-par$priorGuess)*par$priorCertainty ) )
}
# How much evidence do we have? Specifically, given a set of samples from the
# posterior disribution over the rate, what is the posterior probability that
# the true rate is above 50%?
evidenceLevel <- function( posteriorRate ) {
return( mean(posteriorRate >.5 ) )
}
# Make a decision whether to bet. There's a required level of evidence needed
# in order to bet. If it is exceeded, then bet: if not then don't
makeChoice <- function( posteriorRate ) {
evidence <- evidenceLevel( posteriorRate ) # check the evidence
if( evidence > par$evidenceThreshold ) return( 1 ) # bet on "heads"
if( evidence < 1-par$evidenceThreshold ) return( -1 ) # bet on "tails"
return( 0 ) # otherwise don't bet
}
# Get the updated particles. The input is the set of particles as they were
# before any decision/bet was made. The ordering of "update" then "change"
# is to ensure that, when the bet is made on the *next* trial, the learner
# has accounted for the possibility of a very recent change
updateParticles <- function( posteriorRate, bet, outcome ) {
# if the model does not bet, show outcome and update particles
if( bet == 0 ) {
if( outcome==1 ) { # observe outcome 1
w <- posteriorRate
} else { # observe outcome -1
w <- 1-posteriorRate
}
w <- w/sum(w) # nomalised weights
posteriorRate <- sample(posteriorRate, par$nParticles, TRUE, w) # resample
}
# things may change before the next trial arrives:
ind <- runif( par$nParticles ) < par$changeProb # which particles "reset"?
posteriorRate[ind] <- sampleFromRatePrior( sum(ind) ) # reset from prior
return( posteriorRate )
}
# --- run model ---
nTrials <- length(seq)
# define a matrix containing model output
out <- matrix(NA, nTrials, 4)
colnames(out) <- c("sequence","observed","bet","evidence")
out[,"sequence"] <- seq # record the true sequence
# run
posteriorRate <- sampleFromRatePrior()
for( trial in 1:nTrials ){
out[trial,"evidence"] <- evidenceLevel( posteriorRate ) # evidence as it stands right now (including changes)
out[trial,"bet"] <- makeChoice( posteriorRate ) # make a decision
out[trial,"observed"] <- ifelse( out[trial,"bet"]==0, out[trial,"sequence"], 0 ) # what the model saw
posteriorRate <- updateParticles( posteriorRate, out[trial,"bet"], seq[trial] ) # update for next trial
}
# plot?
if( plot ) plotChoices( out, par )
return(out)
}
# define a sequence-generating function
makeSequence <- function( trials=50, prob=.75, changeRate=.02 ) {
seq <- vector(length=trials)
for( t in 1:trials) {
if( runif(1) < changeRate ) prob <- 1-prob
seq[t] <- ifelse( runif(1) < prob , 1, -1)
}
return(seq)
}
# a simple plotting function
plotChoices <- function( out, par, coloured=TRUE ) {
# read from input
bet <- out[,"bet"]
evidence <- out[,"evidence"]
observed <- out[,"observed"]
nTrials <- length(bet)
thresh <- par$evidenceThreshold
# set up plot
plot.new()
plot.window(xlim=c(0,nTrials),ylim=c(0,1))
axis(1)
axis(2)
lines(0:nTrials,c(.5,evidence),type="l",col="grey30")
if( coloured ) {
# coloured version
lines((1:nTrials)[observed==1],evidence[observed==1],pch=19,col="red",type="p")
lines((1:nTrials)[observed==-1],evidence[observed==-1],pch=19,col="blue",type="p")
lines((1:nTrials)[bet!=0],evidence[bet!=0],pch=19,col="black",type="p")
} else {
# greyscale version
lines((1:nTrials)[observed==1],evidence[observed==1],pch=19,col="black",type="p")
lines((1:nTrials)[observed==-1],evidence[observed==-1],pch=19,col="white",type="p")
lines((1:nTrials)[observed==-1],evidence[observed==-1],pch=1,col="black",type="p")
lines((1:nTrials)[bet!=0],evidence[bet!=0],pch=3,col="black",type="p")
}
abline(h=thresh,lty=2)
abline(h=1-thresh,lty=2)
title(xlab="Trial Number", ylab="Model Confidence")
}
runModel(plot=FALSE)
setwd('~/ObserveBet/')
folders = list.dirs(path = 'TaskData', recursive = FALSE);
folders
library(rstan)
library(stringr)
#Fits a stan model to subject data (.csv) and outputs model-based regressors into .txt files
folders = list.dirs(path = 'TaskData', recursive = FALSE);
folders
dir=folders[1]
behavFiles = list.files(path = dir, pattern = 'behav.behav*.csv');
behavFiles
behavFiles = list.files(path = dir, pattern = '*.csv');
behavFiles
behavFiles = list.files(path = dir, pattern = 'behav.behav*.csv');
behavFiles
behavFiles = list.files(path = dir, pattern = 'behav.behav*.csv');
behavFiles
behavFiles = list.files(path = dir, pattern = '*behav.behav*.csv');
behavFiles
behavFiles = list.files(path = dir, pattern = '.*behav.behav.*.csv');
behavFiles
behavFiles = list.files(path = dir, pattern = 'behav.behav.*.csv');
behavFiles
N_SAMPLES = 0;
N_TRIALS = 50;
N_SUBJECTS = 1;
SUBJECT = NULL;
TRIAL_NUM = NULL;
OBSERVATION = NULL;
RESPONSE = NULL;
for (i in 1:length(files)){
d <- read.csv(paste(dir, '/', files[i], sep = ""), header=FALSE)
N_SAMPLES = N_SAMPLES + 50;
SUBJECT = c(SUBJECT, rep(1,50));
TRIAL_NUM = c(TRIAL_NUM, 1:50);
OBSERVATION = c(OBSERVATION, d[,2]);
RESPONSE = c(RESPONSE, d[,1])
}
N_SAMPLES = 0;
N_TRIALS = 50;
N_SUBJECTS = 1;
SUBJECT = NULL;
TRIAL_NUM = NULL;
OBSERVATION = NULL;
RESPONSE = NULL;
for (i in 1:length(behavFiles)){
d <- read.csv(paste(dir, '/', files[i], sep = ""), header=FALSE)
N_SAMPLES = N_SAMPLES + 50;
SUBJECT = c(SUBJECT, rep(1,50));
TRIAL_NUM = c(TRIAL_NUM, 1:50);
OBSERVATION = c(OBSERVATION, d[,2]);
RESPONSE = c(RESPONSE, d[,1])
}
N_SAMPLES = 0;
N_TRIALS = 50;
N_SUBJECTS = 1;
SUBJECT = NULL;
TRIAL_NUM = NULL;
OBSERVATION = NULL;
RESPONSE = NULL;
for (i in 1:length(behavFiles)){
d <- read.csv(paste(dir, '/', behavFiles[i], sep = ""), header=FALSE)
N_SAMPLES = N_SAMPLES + 50;
SUBJECT = c(SUBJECT, rep(1,50));
TRIAL_NUM = c(TRIAL_NUM, 1:50);
OBSERVATION = c(OBSERVATION, d[,2]);
RESPONSE = c(RESPONSE, d[,1])
}
modelIn <- list(
N_SAMPLES = N_SAMPLES,
N_TRIALS = N_TRIALS,
N_SUBJECTS = N_SUBJECTS,
SUBJECT = SUBJECT,
TRIAL_NUM = TRIAL_NUM,
OBSERVATION = OBSERVATION,
RESPONSE = RESPONSE
)
ITER = 2000
CHAINS = 4
#Automatically detect cores and run Stan chains in parallel to speed it up
rstan_options(auto_write = TRUE)
options(mc.cores = parallel::detectCores())
#Grab model code and run Stan fit
modelcode <- paste(readLines('obsModel.stan'), collapse = '\n')
stanFit = stan(model_code=modelcode, data=modelIn, iter=ITER, chains=CHAINS)
fitPar = extract(stanFit, permuted='true')
#Get median value of parameters
alpha = median(fitPar$alpha) #decay parameter
d0 = median(fitPar$d0) #Starting threshold
d1 = median(fitPar$d1) #Ending threshold
c = median(fitPar$c) #Proportion of the way through a block the threshold starts changing
N_TRIALS = 50
d_rate <- (d0 - d1)/(N_TRIALS*(1-c));
d_rate
scanFiles = list.files(path = dir, pattern = 'behav.00*.csv');
scanFiles
scanFiles = list.files(path = dir, pattern = 'behav.00.*.csv');
scanFiles
N_SAMPLES = 0;
N_TRIALS = 50;
N_SUBJECTS = 1;
SUBJECT = NULL;
TRIAL_NUM = NULL;
OBSERVATION = NULL;
RESPONSE = NULL;
for (i in 1:length(scanFiles)){
d <- read.csv(paste(dir, '/', scanFiles[i], sep = ""), header=FALSE)
N_SAMPLES = N_SAMPLES + 50;
SUBJECT = c(SUBJECT, rep(1,50));
TRIAL_NUM = c(TRIAL_NUM, 1:50);
OBSERVATION = c(OBSERVATION, d[,2]);
RESPONSE = c(RESPONSE, d[,1])
}
d = NULL
N_SAMPLES = 0;
N_TRIALS = 50;
N_SUBJECTS = 1;
SUBJECT = NULL;
TRIAL_NUM = NULL;
OBSERVATION = NULL;
RESPONSE = NULL;
for (i in 1:length(scanFiles)){
d <- read.csv(paste(dir, '/', scanFiles[i], sep = ""), header=FALSE)
N_SAMPLES = N_SAMPLES + 50;
SUBJECT = c(SUBJECT, rep(1,50));
TRIAL_NUM = c(TRIAL_NUM, 1:50);
OBSERVATION = c(OBSERVATION, d[,2]);
RESPONSE = c(RESPONSE, d[,1])
}
d = NULL
for (i in 1:N_SAMPLES) {
if(TRIAL_NUM[i] < (c*N_TRIALS)){
d[i] <- d0;
}
else{
d[i] <- d0 - d_rate*(TRIAL_NUM[i] - c*N_TRIALS);
}
if(TRIAL_NUM[i] == 1){
e[i] <- 0;
}
else{
e[i] <- (1 - alpha)*e[i-1] + OBSERVATION[i-1];
}
}
d = NULL
e = NULL
for (i in 1:N_SAMPLES) {
if(TRIAL_NUM[i] < (c*N_TRIALS)){
d[i] <- d0;
}
else{
d[i] <- d0 - d_rate*(TRIAL_NUM[i] - c*N_TRIALS);
}
if(TRIAL_NUM[i] == 1){
e[i] <- 0;
}
else{
e[i] <- (1 - alpha)*e[i-1] + OBSERVATION[i-1];
}
}
e
evidence = e
thresh = d
#Make up some regressors!
#Confidence is the difference between evidence and threshold when you place a bet
conf = RESPONSE*(evidence - (RESPONSE*thresh));
#Evidence when you make an observe action
evOb = evidence*OBSERVATION
#Belief state is just the same as evidence
beliefState = evidence;
#Surprise is the diff
surprise = rep(0,length(evidence))
surprise[evOb < 0] = abs(evOb[evOb < 0])
surprise
evOb
OBSERVATION
#Confidence is the difference between evidence and threshold when you place a bet
conf = RESPONSE*(evidence - (RESPONSE*thresh));
#Evidence in favor of what was just observed (positive means you saw what you have evidence for, negative means what you saw is in conflict with what you have evidence for)
evOb = evidence*OBSERVATION
#Belief state is just the same as evidence
beliefState = evidence;
#Surprise is wgeb evOb is negative (i.e. you saw something that conflicts with your evidence/expectations)
surprise = rep(0,length(evidence))
surprise[evOb < 0] = abs(evOb[evOb < 0])
#Support is when evOb is positive (i.e. you saw something that is in line with your evidence/expectations)
support = rep(0, length(evidence))
support[evOb > 0] = evOb[evOb > 0]
opOnFiles = list.files(path = dir, pattern = 'Observe.run00*');
outOnFiles = list.files(path = dir, pattern = 'outcomeOn.run00*');
opOnFiles
outOnFiles
#Fits a stan model to subject data (.csv) and outputs model-based regressors into .txt files
library(rstan)
library(stringr)
modelSubj <- function(dir){
#Takes a directory with subject data (that the matlab script 'observeBetRegressors' has already been run on).
#Fits a Stan model to the data and outputs .txt files to be used as regressors for fmri data
#Grab all files from BEHAVIORAL sessions (not scans), fit data to that
behavFiles = list.files(path = dir, pattern = 'behav.behav.*.csv');
#Put the data from all files together
N_SAMPLES = 0;
N_TRIALS = 50;
N_SUBJECTS = 1;
SUBJECT = NULL;
TRIAL_NUM = NULL;
OBSERVATION = NULL;
RESPONSE = NULL;
for (i in 1:length(behavFiles)){
d <- read.csv(paste(dir, '/', behavFiles[i], sep = ""), header=FALSE)
N_SAMPLES = N_SAMPLES + 50;
SUBJECT = c(SUBJECT, rep(1,50));
TRIAL_NUM = c(TRIAL_NUM, 1:50);
OBSERVATION = c(OBSERVATION, d[,2]);
RESPONSE = c(RESPONSE, d[,1])
}
#Prepare the data for Stan
modelIn <- list(
N_SAMPLES = N_SAMPLES,
N_TRIALS = N_TRIALS,
N_SUBJECTS = N_SUBJECTS,
SUBJECT = SUBJECT,
TRIAL_NUM = TRIAL_NUM,
OBSERVATION = OBSERVATION,
RESPONSE = RESPONSE
)
#Parameters for running the Stan model
ITER = 2000
CHAINS = 4
#Automatically detect cores and run Stan chains in parallel to speed it up
rstan_options(auto_write = TRUE)
options(mc.cores = parallel::detectCores())
#Grab model code and run Stan fit
modelcode <- paste(readLines('obsModel.stan'), collapse = '\n')
stanFit = stan(model_code=modelcode, data=modelIn, iter=ITER, chains=CHAINS)
#Extract model parameters
fitPar = extract(stanFit, permuted='true')
#Get median value of parameters
alpha = median(fitPar$alpha) #decay parameter
d0 = median(fitPar$d0) #Starting threshold
d1 = median(fitPar$d1) #Ending threshold
c = median(fitPar$c) #Proportion of the way through a block the threshold starts changing
d_rate <- (d0 - d1)/(N_TRIALS*(1-c));
#Read in data for scans
scanFiles = list.files(path = dir, pattern = 'behav.00.*.csv');
#Put the data from scan files together
N_SAMPLES = 0;
N_TRIALS = 50;
N_SUBJECTS = 1;
SUBJECT = NULL;
TRIAL_NUM = NULL;
OBSERVATION = NULL;
RESPONSE = NULL;
for (i in 1:length(scanFiles)){
d <- read.csv(paste(dir, '/', scanFiles[i], sep = ""), header=FALSE)
N_SAMPLES = N_SAMPLES + 50;
SUBJECT = c(SUBJECT, rep(1,50));
TRIAL_NUM = c(TRIAL_NUM, 1:50);
OBSERVATION = c(OBSERVATION, d[,2]);
RESPONSE = c(RESPONSE, d[,1])
}
#Generate threshold and evidence values for the scan runs using the behavior run parameters
d = NULL
e = NULL
for (i in 1:N_SAMPLES) {
if(TRIAL_NUM[i] < (c*N_TRIALS)){
d[i] <- d0;
}
else{
d[i] <- d0 - d_rate*(TRIAL_NUM[i] - c*N_TRIALS);
}
if(TRIAL_NUM[i] == 1){
e[i] <- 0;
}
else{
e[i] <- (1 - alpha)*e[i-1] + OBSERVATION[i-1];
}
}
# e is now the evidence (or belief-state) on each trial, and d is the threshold on each trial
evidence = e
thresh = d
#Make up some regressors!
#Confidence is the difference between evidence and threshold when you place a bet
conf = RESPONSE*(evidence - (RESPONSE*thresh));
#Evidence in favor of what was just observed (positive means you saw what you have evidence for, negative means what you saw is in conflict with what you have evidence for)
evOb = evidence*OBSERVATION
#Belief state is just the same as evidence
beliefState = evidence;
#Surprise is wgeb evOb is negative (i.e. you saw something that conflicts with your evidence/expectations)
surprise = rep(0,length(evidence))
surprise[evOb < 0] = abs(evOb[evOb < 0])
#Support is when evOb is positive (i.e. you saw something that is in line with your evidence/expectations)
support = rep(0, length(evidence))
support[evOb > 0] = evOb[evOb > 0]
#Get the files that have the timestamps for when the option and outcomes come on
opOnFiles = list.files(path = dir, pattern = 'Observe.run00*');
outOnFiles = list.files(path = dir, pattern = 'outcomeOn.run00*');
#Loop through the option on and outcome on files
for(i in 1:length(opOnFiles)){
opFile = paste(dir, '/',opOnFiles[i], sep = "")
outFile = paste(dir, '/',outOnFiles[i], sep = "")
#Read in file
opOn = read.table(opFile)
outOn = read.table(outFile)
#Strip out the third column (which has the regressor value) and replace with the parametric modulator value for each of our paramters
opOn[,3] = NULL
outOn[,3] = NULL
confTable = cbind(opOn, conf[(1 + (i- 1)*50):(i*50)])
belTable = cbind(opOn, beliefState[(1 + (i- 1)*50):(i*50)])
surpriseTable = cbind(outOn, surprise[(1 + (i- 1)*50):(i*50)])
supportTable = cbind(outOn, support[(1 + (i- 1)*50):(i*50)])
#Write to files
confFile = str_replace(opFile, 'Observe', 'confidence')
write.table(confTable, file = confFile, col.names = FALSE, row.names = FALSE, sep='\t')
beliefFile = str_replace(opFile, 'Observe', 'belief')
write.table(belTable, file = beliefFile, col.names = FALSE, row.names = FALSE, sep='\t')
surpFile = str_replace(outFile, 'outcomeOn', 'surprise')
write.table(surpriseTable, file = surpFile, col.names = FALSE, row.names = FALSE, sep='\t')
suppFile = str_replace(outFile, 'outcomeOn', 'support')
write.table(supportTable, file = suppFile, col.names = FALSE, row.names = FALSE, sep='\t')
}
}
folders = list.dirs(path = 'TaskData', recursive = FALSE);
for (i in 1:length(folders)){
modelSubj(folders[i])
}
i
folders
modelSubj(folders[9])
modelSubj(folders[2])
folders[2]
for (i in 11:length(folders)){
modelSubj(folders[i])
}
